{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcdf3ab8",
   "metadata": {},
   "source": [
    "# Normal Numpy script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "226d88fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tracemalloc\n",
    "import numpy as np\n",
    "import timeit\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3676d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory(cosine_sim_function, n_items, embedding_size, float_type='float64', function_kwargs=None):\n",
    "    embeddings = np.random.randn(n_items, embedding_size).astype(float_type)\n",
    "    tracemalloc.clear_traces()\n",
    "    tracemalloc.start()\n",
    "    if function_kwargs is not None:\n",
    "        similarity = cosine_sim_function(embeddings, **function_kwargs)\n",
    "    else:\n",
    "        similarity = cosine_sim_function(embeddings)\n",
    "    _, max_size = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    if isinstance(similarity, scipy.sparse.csr_matrix):\n",
    "        matrix_bytes = similarity.data.nbytes + similarity.indptr.nbytes + similarity.indices.nbytes\n",
    "    else:\n",
    "        matrix_bytes = similarity.nbytes\n",
    "    return max_size, matrix_bytes\n",
    "\n",
    "def get_time(cosine_sim_function, n_items, embedding_size, float_type='float64', n=10, function_kwargs=None):\n",
    "    embeddings = np.random.randn(n_items, embedding_size).astype(float_type)\n",
    "\n",
    "    def _similarity():\n",
    "        if function_kwargs is not None:\n",
    "            cosine_sim_function(embeddings, **function_kwargs)\n",
    "        else:\n",
    "            cosine_sim_function(embeddings)\n",
    "\n",
    "    result = timeit.timeit(stmt='_similarity()', globals=locals(), number=n)\n",
    "    return result / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c17edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_size = 100\n",
    "# step = int(1E3)\n",
    "# n_items = range(1, int(1E4) + step + 1, step)\n",
    "\n",
    "# max_memory = []\n",
    "# matrix_memory = []\n",
    "# execution_time = []\n",
    "# for n in n_items:\n",
    "#     max_size, matrix_size = get_memory(cosine_similarity, n, embedding_size)\n",
    "#     _time = get_time(cosine_similarity, n, embedding_size)\n",
    "#     max_memory.append(max_size)\n",
    "#     matrix_memory.append(matrix_size)\n",
    "#     execution_time.append(_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd81a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_memory(n_items, max_memory, matrix_memory):\n",
    "    plt.figure(facecolor='white')\n",
    "    plt.plot(n_items, [n / 1E9 for n in max_memory], color=\"cyan\", label=\"Max memory\")\n",
    "    plt.plot(n_items, [n / 1E9 for n in matrix_memory], color=\"purple\", label=\"Matrix memory\")\n",
    "    plt.scatter(n_items, [8 * n**2 / 1E9 for n in n_items], color=\"green\", marker=\"*\", label=\"8 bytes * n^2\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.ylabel(\"GB\"), plt.xlabel(\"N items\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_time(n_items, execution_time):\n",
    "    plt.figure(facecolor='white')\n",
    "    plt.plot(n_items, execution_time, color=\"purple\", label=\"Execution time\")\n",
    "    coeff_2, coeff_1, coeff_0 = np.polyfit(n_items, execution_time, 2)\n",
    "    plt.scatter(n_items, [coeff_0 + coeff_1 * n + coeff_2 * n **2 for n in n_items], color=\"green\", marker=\"*\", label=\"Seconds\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f0f64b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_memory(n_items, max_memory, matrix_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4829f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_time(n_items, execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f312b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# n_items_big = range(0, int(1E6) + 1, int(1E5))\n",
    "# plt.figure(facecolor='white')\n",
    "# plt.scatter(n_items_big, [8 * n**2 / 1E9 for n in n_items_big], color=\"green\", marker=\"*\", label=\"Memory in GB\")\n",
    "# plt.legend(loc=\"upper left\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(facecolor='white')\n",
    "# coeff_2, coeff_1, coeff_0 = np.polyfit(n_items, execution_time, 2)\n",
    "# plt.scatter(n_items_big, [(coeff_0 + coeff_1 * n + coeff_2 * n **2) / 3600 for n in n_items_big], color=\"green\", marker=\"*\", label=\"Hours\")\n",
    "# plt.legend(loc=\"upper left\")\n",
    "# plt.show()\n",
    "\n",
    "# coeff_2, coeff_1, coeff_0 = np.polyfit(n_items, execution_time, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9d695",
   "metadata": {},
   "source": [
    "## SkLearn cosine_similarity with 1M items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19474b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_size = 300\n",
    "# n_items = int(1E6)\n",
    "\n",
    "# embeddings = np.random.randn(n_items, embedding_size)\n",
    "# cosine_similarity(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e812a054",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{bmatrix}\n",
    "a_1 & a_2 & a_3 \\\\\n",
    "b_1 & b_2 & b_3 \\\\\n",
    "c_1 & c_2 & c_3 \\\\\n",
    "... & ... & ... \\\\\n",
    "z_1 & z_2 & z_3 \n",
    "\\end{bmatrix}_{n_{items} \\times M}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b6f0ca",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{bmatrix}\n",
    "a_1 & a_2 & a_3 \\\\\n",
    "b_1 & b_2 & b_3 \\\\\n",
    "c_1 & c_2 & c_3 \\\\\n",
    "... & ... & ... \\\\\n",
    "z_1 & z_2 & z_3 \n",
    "\\end{bmatrix}_{n_{items} \\times M}\n",
    "\\times\n",
    "\\begin{bmatrix}\n",
    "a_1 & b_1 & c_1 & ... & z_1 \\\\\n",
    "a_2 & b_2 & c_2 & ... & z_2 \\\\\n",
    "a_3 & b_3 & c_3 & ... & z_3\n",
    "\\end{bmatrix}_{M \\times n_{items} }\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a \\cdot a & a \\cdot b & a \\cdot c & ... & a \\cdot z \\\\\n",
    "b \\cdot a & b \\cdot b & b \\cdot c & ... & b \\cdot z \\\\\n",
    "c \\cdot a & c \\cdot b & c \\cdot c & ... & c \\cdot z \\\\\n",
    "... & ... & ... & ... & ... \\\\\n",
    "z \\cdot a & z \\cdot b & z \\cdot c & ... & z \\cdot z \\\\\n",
    "\\end{bmatrix}_{n_{items} \\times n_{items}}\n",
    "\\leftarrow\\text{Similarity Matrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192cf879",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{bmatrix}\n",
    "a_1 & a_2 & a_3 \\\\\n",
    "b_1 & b_2 & b_3 \\\\\n",
    "... & ... & ... \\\\\n",
    "k_1 & k_2 & k_3 \n",
    "\\end{bmatrix}\n",
    "\\times\n",
    "\\begin{bmatrix}\n",
    "a_1 & b_1 & c_1 & ... & z_1 \\\\\n",
    "a_2 & b_2 & c_2 & ... & z_2 \\\\\n",
    "a_3 & b_3 & c_3 & ... & z_3 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a \\cdot a & a \\cdot b & a \\cdot c & ... & a \\cdot z \\\\\n",
    "b \\cdot a & b \\cdot b & b \\cdot c & ... & b \\cdot z \\\\\n",
    "... & ... & ... & ... & ... \\\\\n",
    "k \\cdot a & k \\cdot b & k \\cdot c & ... & k \\cdot z \\\\\n",
    "\\end{bmatrix}_{n_{items} \\times n_{items}}\n",
    "\\leftarrow\\text{Similarity Matrix}\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "k_1 & k_2 & k_3 \\\\\n",
    "l_1 & l_2 & l_3 \\\\\n",
    "... & ... & ... \\\\\n",
    "z_1 & z_2 & z_3 \n",
    "\\end{bmatrix}\n",
    "\\times\n",
    "\\begin{bmatrix}\n",
    "a_1 & b_1 & c_1 & ... & z_1 \\\\\n",
    "a_2 & b_2 & c_2 & ... & z_2 \\\\\n",
    "a_3 & b_3 & c_3 & ... & z_3 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "k \\cdot a & k \\cdot b & k \\cdot c & ... & k \\cdot z \\\\\n",
    "l \\cdot a & l \\cdot b & l \\cdot c & ... & l \\cdot z \\\\\n",
    "... & ... & ... & ... & ... \\\\\n",
    "z \\cdot a & z \\cdot b & z \\cdot c & ... & z \\cdot z \\\\\n",
    "\\end{bmatrix}_{n_{items} \\times n_{items}}\n",
    "\\leftarrow\\text{Similarity Matrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e63f00",
   "metadata": {},
   "source": [
    "## Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07541300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import math\n",
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "import numba\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from numba_argpartition import np_argpartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43aac670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "LOGGER = logging.getLogger()\n",
    "LOGGER.setLevel(logging.DEBUG)\n",
    "\n",
    "def get_chunk_size_per_thread(n_items, top_k, max_memory_bytes=None):\n",
    "    M = psutil.virtual_memory().available\n",
    "    if max_memory_bytes:\n",
    "        if max_memory_bytes > M:\n",
    "            raise ValueError(f\"Requested maximum memory to use {max_memory_bytes} is bigger than the system's available memory {M}\")\n",
    "        else:\n",
    "            M = max_memory_bytes\n",
    "\n",
    "    # get maximum possible matrix of size chunk_size x chunk_size given available memory\n",
    "    chunk_size = (M / (2 * 8) - (2 * n_items * top_k + n_items)) / n_items  # 8 bytes for a float64 or double type\n",
    "    N = numba.get_num_threads()\n",
    "    chunk_size_per_thread = math.floor(chunk_size / N)\n",
    "    print(f\"Memory available: {M / 1E9:.2f} GB\")\n",
    "    print(f\"Number of threads: {N}\")\n",
    "    print(f\"Chunk size per thread: {chunk_size_per_thread}\")\n",
    "    return chunk_size_per_thread  \n",
    "\n",
    "@njit(parallel=False) #. noting to parallaleize in this function will raise a warning if used\n",
    "def to_sparse(m, top_k):\n",
    "    n_rows, n_cols = m.shape\n",
    "    top_k_j = np.argpartition(m, -top_k)[:, -top_k:]\n",
    "    values = np.take_along_axis(m, top_k_j, axis=1).flatten()\n",
    "    indices = top_k_j.flatten()\n",
    "    return values, indices\n",
    "    \n",
    "@njit(parallel=True)\n",
    "def chunked_dot(x, y, top_k, chunk_size):\n",
    "    n_rows = len(x)\n",
    "    n_non_zero = n_rows * top_k\n",
    "    all_values, all_indices, all_indptr = np.empty(n_non_zero), np.empty(n_non_zero), np.empty(n_rows + 1)\n",
    "    all_indptr[0] = 0\n",
    "    N_THREADS = numba.get_num_threads()\n",
    "#     numba.set_num_threads(1)\n",
    "    for i in prange(0, math.ceil(len(x) / chunk_size)):\n",
    "        start_row_i = i * chunk_size\n",
    "        end_row_i = (i + 1) * chunk_size\n",
    "        chunk_m = np.dot(x[start_row_i: end_row_i], y)\n",
    "        values, indices = to_sparse(chunk_m, top_k)\n",
    "        all_values[start_row_i * top_k: end_row_i * top_k] = values\n",
    "        all_indices[start_row_i * top_k: end_row_i * top_k] = indices\n",
    "    numba.set_num_threads(N_THREADS)\n",
    "    # standard CSR form representation\n",
    "    all_indptr = np.arange(0, top_k * (1 + n_rows), top_k)\n",
    "    return all_values, all_indices, all_indptr\n",
    "        \n",
    "def warm_up_numba_function():\n",
    "    x = np.random.randn(10000, 10).astype('double')\n",
    "    chunked_dot(x, x.T, 3)\n",
    "    \n",
    "        \n",
    "def cosine_similarity_top_k(m, top_k=None, max_memory_bytes=None):\n",
    "    n_rows = m.shape[0]\n",
    "    if top_k is None:\n",
    "        top_k = n_rows\n",
    "#     warm_up_numba_function()\n",
    "    chunk_size_per_thread = get_chunk_size_per_thread(n_rows, top_k, max_memory_bytes)\n",
    "    values, indices, indptr = chunked_dot(m, m.T, top_k, chunk_size_per_thread)\n",
    "    return csr_matrix((values, indices, indptr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976d4ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory available: 10.00 GB\n",
      "Number of threads: 16\n",
      "Chunk size per thread: 378\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 100\n",
    "step = int(1E4)\n",
    "max_n_items = int(1E5)\n",
    "n_items = range(step, max_n_items + 1, step)\n",
    "max_memory_bytes = 10E9\n",
    "\n",
    "max_memory = []\n",
    "matrix_memory = []\n",
    "execution_time = []\n",
    "for n in n_items:\n",
    "    display(n, clear=True)\n",
    "    function_kwargs = {\"top_k\": 100, \"max_memory_bytes\": max_memory_bytes}\n",
    "    max_size, matrix_size = get_memory(cosine_similarity_top_k, n, embedding_size, function_kwargs=function_kwargs)\n",
    "#     _time = get_time(cosine_similarity_top_k, n, embedding_size, function_kwargs=function_kwargs)\n",
    "    max_memory.append(max_size)\n",
    "    matrix_memory.append(matrix_size)\n",
    "#     execution_time.append(_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_memory(n_items, max_memory, matrix_memory)\n",
    "plt.show()\n",
    "# plot_time(n_items, execution_time)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bcfa2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.304"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def memory_cosine_similarity_top_k(n_items, embedding_size, top_k, chunk_size, n_threads):\n",
    "    sparse_matrix_memory = (n_items * top_k) * 2 + n_items  # data + indices + indptr\n",
    "    per_thread_memory = (chunk_size * n_items) * 2 * n_threads  # (chunk dot product result + argpartition output matrix) x number of threads\n",
    "    return (sparse_matrix_memory + per_thread_memory) * 8 / 1E9\n",
    "\n",
    "chunk_size = 2981\n",
    "n_items = 1E6\n",
    "embedding_size = 100\n",
    "top_k = 100\n",
    "n_threads = 1\n",
    "memory_cosine_similarity_top_k(n_items, embedding_size, top_k, chunk_size, n_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9499b275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa54c975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
